{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nlp final project\n",
    "\n",
    "1. Yaniv Gabay - 205745615 - yanivga@edu.hac.ac.il\n",
    "2. Shahar Asher - 209305408 - shaharas@edu.hac.ac.il\n",
    "3. Hadar Liel Harush - 211721568 - hadarhar@edu.hac.ac.il\n",
    "## Eminem song generator\n",
    "\n",
    "This project will compare different models, all trained on the legendary hip-hop artist Eminem lyrics.\n",
    "We want to expirment with different models, our own model, different apis, to see and compare the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to be added?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yanivg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yanivg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######imports\n",
    "\n",
    "#pip install allennlp\n",
    "#pip install flair\n",
    "#pip install pronouncing\n",
    "import torch\n",
    "import pandas as pd\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings, ELMoEmbeddings,TransformerWordEmbeddings\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "import pronouncing\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Make sure to download NLTK data (e.g., WordNet, Punkt tokenizer models)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize lemmatizer and tokenizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with encoding utf-8: 'utf-8' codec can't decode byte 0x92 in position 6: invalid start byte\n",
      "Success with encoding: latin1\n",
      "                        Album_Name       Song_Name  \\\n",
      "0  Music To Be Murdered By: Side B  Alfred (Intro)   \n",
      "1  Music To Be Murdered By: Side B     Black Magic   \n",
      "2  Music To Be Murdered By: Side B  AlfredÂ’s Theme   \n",
      "3  Music To Be Murdered By: Side B       Tone Deaf   \n",
      "4  Music To Be Murdered By: Side B  Book of Rhymes   \n",
      "\n",
      "                                              Lyrics  \\\n",
      "0  [Intro: Alfred Hitchcock]\\nThus far, this albu...   \n",
      "1  [Chorus: Skylar Grey & Eminem]\\nBlack magic, n...   \n",
      "2  [Verse 1]\\nBefore I check the mic (Check, chec...   \n",
      "3  [Intro]\\nYeah, I'm sorry (Huh?)\\nWhat did you ...   \n",
      "4  [Intro]\\nI don't smile, I don't frown, get too...   \n",
      "\n",
      "                                           Album_URL   Views  \\\n",
      "0  https://genius.com/albums/Eminem/Music-to-be-m...   24.3K   \n",
      "1  https://genius.com/albums/Eminem/Music-to-be-m...  180.6K   \n",
      "2  https://genius.com/albums/Eminem/Music-to-be-m...  285.6K   \n",
      "3  https://genius.com/albums/Eminem/Music-to-be-m...  210.9K   \n",
      "4  https://genius.com/albums/Eminem/Music-to-be-m...  193.3K   \n",
      "\n",
      "        Release_date Unnamed: 6  \n",
      "0  December 18, 2020        NaN  \n",
      "1  December 18, 2020        NaN  \n",
      "2  December 18, 2020        NaN  \n",
      "3  December 18, 2020        NaN  \n",
      "4  December 18, 2020        NaN  \n",
      "Error exporting the csv file: [Errno 13] Permission denied: 'data_afterImport-1.csv'\n"
     ]
    }
   ],
   "source": [
    "##### Loading the data\n",
    "### we be using <startVerse> <endVerse> <startChorus><endChorus>\n",
    "## to give our model some different between the verses and the choruses.\n",
    "\n",
    "#important to export the data to see the effect\n",
    "#of changes, especilly with a small dataset\n",
    "def export_data(data,stage):\n",
    "    try:\n",
    "        data.to_csv('data_'+stage+'.csv')\n",
    "    except Exception as e:\n",
    "        print(\"Error exporting the csv file:\", e)  \n",
    "#basic import\n",
    "def import_data(location):\n",
    "    df = read_data(location)\n",
    "    return df\n",
    "#read with try except,can add more specific\n",
    "#we try different encoding, you can never know what chars you will find.\n",
    "# this one is working with latin1, but we still left the function\n",
    "#exceptions\n",
    "def read_data(location):\n",
    "    try_encodings = ['utf-8', 'latin1', 'utf-16', 'cp1252', 'ISO-8859-1', 'windows-1252']\n",
    "    for encoding in try_encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(location ,encoding=encoding,delimiter='\\t')\n",
    "            print(f\"Success with encoding: {encoding}\")\n",
    "            print(df.head())\n",
    "            return df\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error with encoding {encoding}: {e}\")\n",
    "####\n",
    "file_loc = './Eminem_Lyrics.csv'\n",
    "df = import_data(file_loc)\n",
    "export_data(df,'afterImport-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      <startSong>\\n<startIntro>\\nThus far, this albu...\n",
      "1      <startSong>\\n<startChorus>\\nBlack magic, night...\n",
      "2      <startSong>\\n<startVerse>\\nBefore I check the ...\n",
      "3      <startSong>\\n<startIntro>\\nYeah, I'm sorry (Hu...\n",
      "4      <startSong>\\n<startIntro>\\nI don't smile, I do...\n",
      "                             ...                        \n",
      "343    <startSong>\\n<startChorus>\\nI know there's som...\n",
      "344    <startSong>\\n<startIntro>\\nYeah, yeah, I get i...\n",
      "345    <startSong>\\n<startVerse>\\nI cut back on the s...\n",
      "346    <startSong>\\n<startIntro>\\nC'mon!\\n\\n<endIntro...\n",
      "347    <startSong>\\n<startIntro>\\nCDs ain't selling n...\n",
      "Name: Lyrics, Length: 348, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#actual messing with the dataset\n",
    "import re\n",
    "\n",
    "\n",
    "def insert_tokens(lyrics):\n",
    "    # Pattern to identify all tags (verses, choruses, etc.)\n",
    "    pattern = re.compile(r'\\[(Verse|Chorus|Intro|Outro)')\n",
    "    \n",
    "    # Placeholder for processed lyrics\n",
    "    processed_lyrics = \"<startSong>\\n\"\n",
    "    last_tag = None\n",
    "\n",
    "    for line in lyrics.split('\\n'):\n",
    "        tag_match = pattern.match(line)\n",
    "        if tag_match:\n",
    "            # Close the previous tag if exists\n",
    "            if last_tag:\n",
    "                processed_lyrics += f\"<end{last_tag}>\\n\"\n",
    "            # Update last_tag and open a new tag\n",
    "            last_tag = tag_match.group(1)  # Capture the tag name (Verse or Chorus)\n",
    "            processed_lyrics += f\"<start{last_tag}>\\n\"\n",
    "        else:\n",
    "            processed_lyrics += line + \"\\n\"\n",
    "\n",
    "    # Close the last opened tag\n",
    "    if last_tag:\n",
    "        processed_lyrics += f\"<end{last_tag}>\\n\"\n",
    "    processed_lyrics += \"<endSong>\"\n",
    "\n",
    "    return processed_lyrics\n",
    "\n",
    "def remove_remaining_tags(lyrics):\n",
    "    # Pattern to match any text within square brackets\n",
    "    pattern = re.compile(r'\\[[^\\]]*\\]')\n",
    "    cleaned_lyrics = re.sub(pattern, '', lyrics)\n",
    "    return cleaned_lyrics\n",
    "\n",
    "def handle_special(lyrics):\n",
    "    #remove \n",
    "    output_string = re.sub(r\"'\", '', lyrics)\n",
    "    return output_string\n",
    "\n",
    "new_df = df['Lyrics'].apply(insert_tokens)\n",
    "\n",
    "print(new_df)\n",
    "export_data(new_df,'afterUniqueTokens')\n",
    "\n",
    "## some songs can have some another tags, like post-chorus,pre etc. \n",
    "## we arent intresnted in those, so we will just delete them in the next step\n",
    "new_df = new_df.apply(remove_remaining_tags)\n",
    "new_df = new_df.apply(handle_special)\n",
    "#lowercase everything\n",
    "new_df = new_df.str.lower()\n",
    "\n",
    "export_data(new_df,'afterLowerAndRemove')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### special chars\n",
    "def remove_non_ascii_and_print(text):\n",
    "    cleaned_text = []\n",
    "    removed_chars = []\n",
    "    for char in text:\n",
    "        if ord(char) < 128:\n",
    "            cleaned_text.append(char)\n",
    "        else:\n",
    "            removed_chars.append(char)\n",
    "    if removed_chars:\n",
    "        print(f\"Removed characters: {''.join(removed_chars)}\")\n",
    "    return ''.join(cleaned_text)\n",
    "clean = new_df.apply(remove_non_ascii_and_print)\n",
    "\n",
    "export_data(clean,'clean')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
