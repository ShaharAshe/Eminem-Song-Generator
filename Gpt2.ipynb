{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eminem Song Lyrics Generation using GPT-2\n",
    "\n",
    "This Jupyter notebook details the process of training a GPT-2 model to generate song lyrics in the style of Eminem, one of the most iconic rappers of all time. Our goal is to capture the essence of Eminem's lyrical style using the power of the GPT-2 transformer model, known for its effectiveness in natural language understanding and generation tasks.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "- **Objective**: To train a GPT-2 model capable of generating song lyrics that mimic Eminem's style.\n",
    "- **Data Source**: The dataset consists of a collection of Eminem's song lyrics, curated to provide a diverse representation of his work.\n",
    "- **Approach**: We utilize a pre-trained GPT-2 model and fine-tune it on the Eminem lyrics dataset, employing specific preprocessing steps to optimize the model's performance for this task.\n",
    "- **Expected Outcome**: A model that generates new lyrics reflecting Eminem's thematic elements, rhyme schemes, and lyrical complexity.\n",
    "\n",
    "By the end of this notebook, we will have a trained model ready to produce Eminem-style song lyrics, along with an evaluation of its performance and insights into the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 50260. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completed. Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######imports\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from utilities import import_data_from_location, handle_special_characters\n",
    "import utilities as util\n",
    "\n",
    "# Initialize the tokenizer and model from the pre-trained 'gpt2' model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Check for GPU availability and set the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Setup completed. Using device: {device}\")\n",
    "\n",
    "special_tokens = {'pad_token': '<PAD>'}\n",
    "special_tokens_dict = {'additional_special_tokens': ['<startsong>', '<endsong>']}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this section, we'll prepare the Eminem song lyrics dataset for training the GPT-2 model. This involves loading the dataset, cleaning the text, tokenizing the lyrics, and organizing the data into a suitable format for the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with encoding utf-8: 'utf-8' codec can't decode byte 0x92 in position 6: invalid start byte\n",
      "Success with encoding: latin1\n",
      "Lyrics after remove_sections: Thus far, this album has provided musical accompaniment to make your passing pleasant\n",
      "Our next number is designed to drown out the sound of shovels\n",
      "Music to be buried by\n",
      "Lyrics after handle_special_characters: Thus far, this album has provided musical accompaniment to make your passing pleasant\n",
      "Our next number is designed to drown out the sound of shovels\n",
      "Music to be buried by\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: á\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ó\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ö\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: âé\n",
      "Removed non-ASCII characters: ó\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: óá\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: áíóé\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ú\n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: â\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: è\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ä\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: âá\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ä\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: àé\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ßé\n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ü\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ï\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ü\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: âé\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ü\n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: ç\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: é\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: àé\n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Removed non-ASCII characters: \n",
      "Lyrics after remove_non_ascii_characters: Thus far, this album has provided musical accompaniment to make your passing pleasant\n",
      "Our next number is designed to drown out the sound of shovels\n",
      "Music to be buried by\n",
      "Lyrics after expanding contractions: Thus far, this album has provided musical accompaniment to make your passing pleasant\n",
      "Our next number is designed to drown out the sound of shovels\n",
      "Music to be buried by\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_loc = './Eminem_Lyrics.csv'\n",
    "songs = util.import_data_from_location(file_loc)\n",
    "\n",
    "def remove_sections(text):\n",
    "    # Define a regular expression pattern to match the song sections and their variations\n",
    "    pattern = r\"\\[(Verse|Intro|Chorus|Interlude|Outro).*?\\]\"\n",
    "    \n",
    "    # Replace the matched patterns with an empty string\n",
    "    cleaned_text = re.sub(pattern, \"\", text)\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "\n",
    "\n",
    "def PreProcess(df,col):\n",
    "    df[col] = df[col].apply(remove_sections)\n",
    "    print(f\"Lyrics after remove_sections: {df[col][0]}\")\n",
    "    df[col] = df[col].apply(util.handle_special_characters)\n",
    "    print(f\"Lyrics after handle_special_characters: {df[col][0]}\")\n",
    "    df[col] = df[col].apply(util.remove_non_ascii_characters)\n",
    "    print(f\"Lyrics after remove_non_ascii_characters: {df[col][0]}\")\n",
    "    df[col] = df[col].apply(util.expand_contractions, args=(util.contractions_dict,))\n",
    "    print(f\"Lyrics after expanding contractions: {df[col][0]}\")\n",
    "    return df\n",
    "\n",
    "preprocessed_songs = PreProcess(songs, 'Lyrics')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define the custom dataset class for song lyrics\n",
    "class SongDataset(Dataset):\n",
    "    \"\"\"A custom Dataset class for song lyrics.\"\"\"\n",
    "    def __init__(self, txt_list, tokenizer, max_length):\n",
    "        \"\"\"Initializes the dataset with tokenized and encoded song lyrics.\"\"\"\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "        # Tokenize and encode each song in the dataset\n",
    "        for txt in txt_list:\n",
    "            encodings = tokenizer('<startsong> ' + txt + ' <endsong>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(encodings['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of songs in the dataset.\"\"\"\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns the tokenized and encoded data of the song at the specified index.\"\"\"\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n",
    "\n",
    "\n",
    "\n",
    "# Assuming `preprocessed_songs` is a list of preprocessed song lyrics\n",
    "dataset = SongDataset(preprocessed_songs, tokenizer, max_length=512)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, labels\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mmasks)\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m/\u001b[39m gradient_accumulation_steps  \u001b[38;5;66;03m# Scale the loss\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     23\u001b[0m perplexity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader) * epochs)\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_perplexities = []\n",
    "# Training loop with gradient accumulation\n",
    "gradient_accumulation_steps = 4  # Adjust as needed for memory management\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()  # Initialize gradients to zero at the start of each epoch\n",
    "\n",
    "    for batch_idx, (input_ids, masks) in enumerate(dataloader):\n",
    "        input_ids, masks = input_ids.to(device), masks.to(device)\n",
    "        outputs = model(input_ids, labels=input_ids, attention_mask=masks)\n",
    "        loss = outputs.loss / gradient_accumulation_steps  # Adjust loss for gradient accumulation\n",
    "        loss.backward()  # Accumulate gradients\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Step the optimizer and scheduler every `gradient_accumulation_steps`\n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()  # Clear gradients after updating weights\n",
    "\n",
    "        # Periodically print the loss, perplexity, and a sample prediction\n",
    "        if batch_idx % 10 == 0:\n",
    "            adjusted_loss = loss.item() * gradient_accumulation_steps  # Adjust the loss back for reporting\n",
    "            perplexity = np.exp(adjusted_loss)\n",
    "            print(f\"Batch {batch_idx}/{len(dataloader)} - Loss: {adjusted_loss:.4f} - Perplexity: {perplexity:.2f}\")\n",
    "\n",
    "            # Decode and display a sample input, target, and prediction for qualitative evaluation\n",
    "            input_sequence = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "            prediction_ids = torch.argmax(outputs.logits, dim=-1)[0]\n",
    "            prediction_sequence = tokenizer.decode(prediction_ids, skip_special_tokens=True)\n",
    "\n",
    "            print(f\"  Input Sequence: {input_sequence}\")\n",
    "            print(f\"  Target Sequence: {input_sequence}\")  # Target is the same as input in language modeling\n",
    "            print(f\"  Prediction: {prediction_sequence}\\n\")\n",
    "\n",
    "    # Compute and report the average loss and perplexity for the epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_perplexity = np.exp(avg_loss)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    epoch_perplexities.append(avg_perplexity)\n",
    "    print(f\"End of Epoch {epoch+1} - Average Loss: {avg_loss:.4f} - Average Perplexity: {avg_perplexity:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loss and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(epoch_losses, epoch_perplexities):\n",
    "    epochs_range = range(1, len(epoch_losses) + 1)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, epoch_losses, label='Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, epoch_perplexities, label='Training Perplexity')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.title('Training Perplexity Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(epoch_losses, epoch_perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of new songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "prompt = \"<startsong>\"\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "generated = generated.to(device)\n",
    "\n",
    "def generate_text_samples(model, tokenizer, prompt, device, num_samples=3):\n",
    "       \"\"\"\n",
    "    Generates text samples with different configurations using the specified model and tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model used for text generation.\n",
    "    - tokenizer: The tokenizer for encoding and decoding the text.\n",
    "    - prompt (str): The initial text to start the generation.\n",
    "    - device: The device (CPU or GPU) on which the model is loaded.\n",
    "    - num_samples (int, optional): The number of samples to generate for each configuration. Default is 3.\n",
    "    \"\"\"\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "\n",
    "    input_ids = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device)\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=device)\n",
    "    # Define different generation configurations\n",
    "    generation_configs = [\n",
    "        {\"config\": {\"temperature\": 0.8, \"top_k\": 50, \"top_p\": 0.95}, \"description\": \"Temperature\"},\n",
    "        {\"config\": {\"temperature\": 1.0, \"top_k\": 30, \"top_p\": 0.95}, \"description\": \"Top-K\"},\n",
    "        {\"config\": {\"temperature\": 1.0, \"top_k\": 0, \"top_p\": 0.85}, \"description\": \"Top-P\"},\n",
    "        {\"config\": {\"temperature\": 1.0, \"top_k\": 50, \"top_p\": 0.95, \"num_beams\": 5, \"early_stopping\": True}, \"description\": \"Beam Search\"},\n",
    "        {\"config\": {\"temperature\": 1.0, \"top_k\": 50, \"top_p\": 0.95, \"repetition_penalty\": 2.0}, \"description\": \"No Repetition Penalty\"},\n",
    "\n",
    "        {\"config\": {\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95, \"repetition_penalty\": 2.5}, \"description\": \"Temperature with High Repetition Penalty\"},\n",
    "        {\"config\": {\"temperature\": 0.9, \"top_k\": 20, \"top_p\": 0.85, \"repetition_penalty\": 2.0, \"no_repeat_ngram_size\": 2}, \"description\": \"Top-K with N-Gram Repetition Prevention\"},\n",
    "        {\"config\": {\"temperature\": 1.0, \"top_k\": 0, \"top_p\": 0.8, \"repetition_penalty\": 2.0, \"no_repeat_ngram_size\": 3}, \"description\": \"Top-P with N-Gram Repetition Prevention\"},\n",
    "        {\"config\": {\"num_beams\": 5, \"early_stopping\": True, \"no_repeat_ngram_size\": 3}, \"description\": \"Beam Search with N-Gram Repetition Prevention\"},\n",
    "        {\"config\": {\"temperature\": 1.0, \"top_k\": 50, \"top_p\": 0.95, \"repetition_penalty\": 3.0, \"no_repeat_ngram_size\": 4}, \"description\": \"No Repetition Penalty with Strong N-Gram Prevention\"}\n",
    "    ]\n",
    "    for config in generation_configs:\n",
    "        print(f\"\\nGenerating with {config['description']} configuration:\")\n",
    "        sample_outputs = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            max_length=300,\n",
    "            num_return_sequences=num_samples,\n",
    "            **{k: v for k, v in config.items() if k != \"description\"}\n",
    "        )\n",
    "\n",
    "        for i, sample_output in enumerate(sample_outputs):\n",
    "            print(f\"{config['description']} Sample {i+1}: {tokenizer.decode(sample_output, skip_special_tokens=True)}\\n\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(\"Generating text samples with different configurations:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Prompt: '<startsong>'\")\n",
    "generate_text_samples(model, tokenizer, prompt=\"<startsong>\", device=device, num_samples=3)\n",
    "print(\"Prompt: 'I'm feeling like a rap god'\")\n",
    "generate_text_samples(model, tokenizer, prompt=\"I'm feeling like a rap god\", device=device, num_samples=2)\n",
    "print(\"Prompt: 'my name is slim shady'\")\n",
    "generate_text_samples(model, tokenizer, prompt=\"my name is slim shady\", device=device, num_samples=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
