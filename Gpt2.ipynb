{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######imports\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "!pip install transformers torch\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "import utilities as util\n",
    "\n",
    "location = \"/Eminem_Lyrics.csv\"\n",
    "songs = util.import_data(location)\n",
    "songs = songs.apply(lambda x: util.clean_text(x))\n",
    "songs = songs.apply(lambda x: util.remove_non_ascii_and_print(x))\n",
    "songs = songs.apply(lambda x: util.expand_contractions(x))\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "special_tokens = {'pad_token': '<PAD>'}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "\n",
    "class SongDataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        for txt in txt_list:\n",
    "            encodings_dict = tokenizer('<startsong> '+ txt + ' <endsong>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n",
    "\n",
    "\n",
    "# Assuming `songs` is a list containing all your song lyrics\n",
    "dataset = SongDataset(songs, tokenizer, max_length=512)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True) \n",
    "\n",
    "\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Move the model to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "epochs = 4\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader) * epochs)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:\n",
    "        b_input_ids, b_labels, b_masks = batch\n",
    "        b_input_ids = b_input_ids.to(device)\n",
    "        b_labels = b_labels.to(device)\n",
    "        b_masks = b_masks.to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        outputs = model(b_input_ids, labels=b_labels, attention_mask=b_masks, token_type_ids=None)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "prompt = \"<startsong>\"\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "generated = generated.to(device)\n",
    "\n",
    "sample_outputs = model.generate(generated, do_sample=True, top_k=50, max_length=300, top_p=0.95, num_return_sequences=3)\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}\\n\\n\".format(i+1, tokenizer.decode(sample_output.tolist(), skip_special_tokens=True)))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
